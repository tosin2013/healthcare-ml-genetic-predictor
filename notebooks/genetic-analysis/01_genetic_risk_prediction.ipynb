{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Risk Prediction Analysis\n",
    "\n",
    "This notebook demonstrates genetic risk prediction using machine learning on OpenShift AI.\n",
    "\n",
    "## Overview\n",
    "- Load and analyze genetic sequence data\n",
    "- Process VEP annotations\n",
    "- Build ML models for risk prediction\n",
    "- Demonstrate real-time processing with Kafka\n",
    "- Monitor scaling and cost attribution\n",
    "\n",
    "Based on research from PMC7613081: Machine learning approaches for genetic risk prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import sys\n",
    "!{sys.executable} -m pip install kafka-python pandas numpy scikit-learn matplotlib seaborn biopython requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqUtils import GC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")\n",
    "print(f\"ðŸ“Š Pandas version: {pd.__version__}\")\n",
    "print(f\"ðŸ§¬ BioPython available\")\n",
    "print(f\"ðŸ“ˆ Scikit-learn available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Sample Genetic Data\n",
    "\n",
    "Create synthetic genetic sequences and risk factors for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample genetic data\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_genetic_sequence(length=100):\n",
    "    \"\"\"Generate a random DNA sequence\"\"\"\n",
    "    bases = ['A', 'T', 'G', 'C']\n",
    "    return ''.join(np.random.choice(bases, length))\n",
    "\n",
    "def calculate_genetic_features(sequence):\n",
    "    \"\"\"Calculate features from genetic sequence\"\"\"\n",
    "    seq_obj = Seq(sequence)\n",
    "    return {\n",
    "        'length': len(sequence),\n",
    "        'gc_content': GC(sequence),\n",
    "        'a_count': sequence.count('A'),\n",
    "        't_count': sequence.count('T'),\n",
    "        'g_count': sequence.count('G'),\n",
    "        'c_count': sequence.count('C'),\n",
    "        'at_ratio': (sequence.count('A') + sequence.count('T')) / len(sequence),\n",
    "        'purine_ratio': (sequence.count('A') + sequence.count('G')) / len(sequence)\n",
    "    }\n",
    "\n",
    "# Generate sample dataset\n",
    "n_samples = 1000\n",
    "genetic_data = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # Generate sequence\n",
    "    sequence = generate_genetic_sequence(np.random.randint(80, 120))\n",
    "    features = calculate_genetic_features(sequence)\n",
    "    \n",
    "    # Simulate risk factors (based on GC content and sequence patterns)\n",
    "    risk_score = (\n",
    "        features['gc_content'] * 0.3 +\n",
    "        features['at_ratio'] * 0.2 +\n",
    "        np.random.normal(0, 10)\n",
    "    )\n",
    "    \n",
    "    # Binary risk classification\n",
    "    high_risk = 1 if risk_score > 25 else 0\n",
    "    \n",
    "    genetic_data.append({\n",
    "        'sample_id': f'SAMPLE_{i:04d}',\n",
    "        'sequence': sequence,\n",
    "        'risk_score': risk_score,\n",
    "        'high_risk': high_risk,\n",
    "        **features\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(genetic_data)\n",
    "print(f\"âœ… Generated {len(df)} genetic samples\")\n",
    "print(f\"ðŸ“Š High risk samples: {df['high_risk'].sum()} ({df['high_risk'].mean()*100:.1f}%)\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# GC Content distribution\n",
    "axes[0,0].hist(df['gc_content'], bins=30, alpha=0.7, color='skyblue')\n",
    "axes[0,0].set_title('GC Content Distribution')\n",
    "axes[0,0].set_xlabel('GC Content (%)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# Risk score by GC content\n",
    "scatter = axes[0,1].scatter(df['gc_content'], df['risk_score'], \n",
    "                           c=df['high_risk'], cmap='RdYlBu', alpha=0.6)\n",
    "axes[0,1].set_title('Risk Score vs GC Content')\n",
    "axes[0,1].set_xlabel('GC Content (%)')\n",
    "axes[0,1].set_ylabel('Risk Score')\n",
    "plt.colorbar(scatter, ax=axes[0,1], label='High Risk')\n",
    "\n",
    "# Sequence length distribution\n",
    "axes[1,0].hist(df['length'], bins=20, alpha=0.7, color='lightgreen')\n",
    "axes[1,0].set_title('Sequence Length Distribution')\n",
    "axes[1,0].set_xlabel('Sequence Length')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "\n",
    "# Risk distribution\n",
    "risk_counts = df['high_risk'].value_counts()\n",
    "axes[1,1].pie(risk_counts.values, labels=['Low Risk', 'High Risk'], \n",
    "              autopct='%1.1f%%', colors=['lightblue', 'salmon'])\n",
    "axes[1,1].set_title('Risk Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nðŸ“Š Summary Statistics:\")\n",
    "print(df[['gc_content', 'length', 'risk_score', 'at_ratio', 'purine_ratio']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine Learning Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for ML\n",
    "feature_columns = ['gc_content', 'length', 'at_ratio', 'purine_ratio', 'a_count', 't_count', 'g_count', 'c_count']\n",
    "X = df[feature_columns]\n",
    "y = df['high_risk']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"ðŸ“Š Training set: {len(X_train)} samples\")\n",
    "print(f\"ðŸ“Š Test set: {len(X_test)} samples\")\n",
    "print(f\"ðŸ“Š Feature columns: {feature_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "print(\"ðŸ¤– Training Random Forest model...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"âœ… Model training completed!\")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nðŸ“ˆ Model Performance:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nðŸŽ¯ Feature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "# Feature Importance\n",
    "axes[1].barh(feature_importance['feature'], feature_importance['importance'])\n",
    "axes[1].set_title('Feature Importance')\n",
    "axes[1].set_xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Model accuracy\n",
    "accuracy = rf_model.score(X_test, y_test)\n",
    "print(f\"\\nðŸŽ¯ Model Accuracy: {accuracy:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
