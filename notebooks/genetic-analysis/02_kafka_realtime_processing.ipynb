{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time Genetic Data Processing with Kafka\n",
    "\n",
    "This notebook demonstrates real-time genetic data processing using Kafka integration.\n",
    "\n",
    "## Features\n",
    "- Connect to Kafka cluster\n",
    "- Send genetic sequences for VEP annotation\n",
    "- Receive and process annotated results\n",
    "- Trigger KEDA scaling events\n",
    "- Monitor cost attribution in real-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "from kafka.errors import KafkaError\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Kafka configuration\n",
    "KAFKA_BOOTSTRAP_SERVERS = os.getenv('KAFKA_BOOTSTRAP_SERVERS', \n",
    "                                   'genetic-data-cluster-kafka-bootstrap.healthcare-ml-demo.svc.cluster.local:9092')\n",
    "RAW_TOPIC = 'genetic-data-raw'\n",
    "ANNOTATED_TOPIC = 'genetic-data-annotated'\n",
    "\n",
    "print(f\"üîó Kafka Bootstrap Servers: {KAFKA_BOOTSTRAP_SERVERS}\")\n",
    "print(f\"üì§ Raw Data Topic: {RAW_TOPIC}\")\n",
    "print(f\"üì• Annotated Data Topic: {ANNOTATED_TOPIC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Kafka Connection Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kafka_producer():\n",
    "    \"\"\"Create Kafka producer with error handling\"\"\"\n",
    "    try:\n",
    "        producer = KafkaProducer(\n",
    "            bootstrap_servers=[KAFKA_BOOTSTRAP_SERVERS],\n",
    "            value_serializer=lambda v: json.dumps(v).encode('utf-8'),\n",
    "            key_serializer=lambda k: k.encode('utf-8') if k else None,\n",
    "            acks='all',\n",
    "            retries=3,\n",
    "            max_in_flight_requests_per_connection=1\n",
    "        )\n",
    "        print(\"‚úÖ Kafka producer created successfully\")\n",
    "        return producer\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to create Kafka producer: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_kafka_consumer(topic, group_id='notebook-consumer'):\n",
    "    \"\"\"Create Kafka consumer with error handling\"\"\"\n",
    "    try:\n",
    "        consumer = KafkaConsumer(\n",
    "            topic,\n",
    "            bootstrap_servers=[KAFKA_BOOTSTRAP_SERVERS],\n",
    "            group_id=group_id,\n",
    "            value_deserializer=lambda m: json.loads(m.decode('utf-8')),\n",
    "            auto_offset_reset='latest',\n",
    "            enable_auto_commit=True\n",
    "        )\n",
    "        print(f\"‚úÖ Kafka consumer created for topic: {topic}\")\n",
    "        return consumer\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to create Kafka consumer: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test connections\n",
    "producer = create_kafka_producer()\n",
    "consumer = create_kafka_consumer(ANNOTATED_TOPIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate and Send Genetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_genetic_sequence(length=100):\n",
    "    \"\"\"Generate a random DNA sequence\"\"\"\n",
    "    bases = ['A', 'T', 'G', 'C']\n",
    "    return ''.join(np.random.choice(bases, length))\n",
    "\n",
    "def create_genetic_message(sequence_id, processing_mode='normal'):\n",
    "    \"\"\"Create a genetic data message for Kafka\"\"\"\n",
    "    sequence = generate_genetic_sequence(np.random.randint(80, 200))\n",
    "    \n",
    "    return {\n",
    "        'sequenceId': sequence_id,\n",
    "        'sequence': sequence,\n",
    "        'species': 'human',\n",
    "        'assembly': 'GRCh38',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'source': 'jupyter-notebook',\n",
    "        'processingMode': processing_mode,\n",
    "        'metadata': {\n",
    "            'length': len(sequence),\n",
    "            'gc_content': (sequence.count('G') + sequence.count('C')) / len(sequence) * 100,\n",
    "            'notebook_session': 'genetic-analysis-demo'\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Test message creation\n",
    "test_message = create_genetic_message('TEST_001')\n",
    "print(\"üìù Sample genetic data message:\")\n",
    "print(json.dumps(test_message, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_genetic_data_batch(producer, num_sequences=10, processing_mode='normal'):\n",
    "    \"\"\"Send a batch of genetic sequences to Kafka\"\"\"\n",
    "    if not producer:\n",
    "        print(\"‚ùå No producer available\")\n",
    "        return []\n",
    "    \n",
    "    sent_messages = []\n",
    "    \n",
    "    for i in range(num_sequences):\n",
    "        sequence_id = f'SEQ_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}_{i:03d}'\n",
    "        message = create_genetic_message(sequence_id, processing_mode)\n",
    "        \n",
    "        try:\n",
    "            # Send to Kafka\n",
    "            future = producer.send(RAW_TOPIC, key=sequence_id, value=message)\n",
    "            result = future.get(timeout=10)\n",
    "            \n",
    "            sent_messages.append({\n",
    "                'sequence_id': sequence_id,\n",
    "                'timestamp': message['timestamp'],\n",
    "                'length': message['metadata']['length'],\n",
    "                'gc_content': message['metadata']['gc_content'],\n",
    "                'processing_mode': processing_mode\n",
    "            })\n",
    "            \n",
    "            print(f\"‚úÖ Sent {sequence_id} (length: {message['metadata']['length']}, GC: {message['metadata']['gc_content']:.1f}%)\")\n",
    "            \n",
    "        except KafkaError as e:\n",
    "            print(f\"‚ùå Failed to send {sequence_id}: {e}\")\n",
    "        \n",
    "        # Small delay between messages\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    producer.flush()\n",
    "    return sent_messages\n",
    "\n",
    "# Send a small batch for testing\n",
    "print(\"üì§ Sending test batch of genetic sequences...\")\n",
    "sent_sequences = send_genetic_data_batch(producer, num_sequences=5)\n",
    "print(f\"\\n‚úÖ Successfully sent {len(sent_sequences)} sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Monitor Annotated Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_annotated_results(consumer, duration_seconds=30):\n",
    "    \"\"\"Monitor and collect annotated results from Kafka\"\"\"\n",
    "    if not consumer:\n",
    "        print(\"‚ùå No consumer available\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"üëÇ Monitoring annotated results for {duration_seconds} seconds...\")\n",
    "    \n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        while time.time() - start_time < duration_seconds:\n",
    "            # Poll for messages with timeout\n",
    "            message_batch = consumer.poll(timeout_ms=1000)\n",
    "            \n",
    "            for topic_partition, messages in message_batch.items():\n",
    "                for message in messages:\n",
    "                    try:\n",
    "                        data = message.value\n",
    "                        results.append({\n",
    "                            'sequence_id': data.get('sequenceId', 'unknown'),\n",
    "                            'status': data.get('status', 'unknown'),\n",
    "                            'variant_count': data.get('variantCount', 0),\n",
    "                            'processing_time': data.get('processingTime', 0),\n",
    "                            'timestamp': data.get('timestamp', ''),\n",
    "                            'source': data.get('source', ''),\n",
    "                            'message': data.get('message', '')\n",
    "                        })\n",
    "                        \n",
    "                        print(f\"üì• Received: {data.get('sequenceId')} - {data.get('status')} - {data.get('variantCount', 0)} variants\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ö†Ô∏è Error processing message: {e}\")\n",
    "            \n",
    "            # Show progress\n",
    "            elapsed = time.time() - start_time\n",
    "            remaining = duration_seconds - elapsed\n",
    "            if int(elapsed) % 5 == 0:  # Update every 5 seconds\n",
    "                print(f\"‚è±Ô∏è Monitoring... {remaining:.0f}s remaining, {len(results)} results received\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚èπÔ∏è Monitoring stopped by user\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Monitoring completed. Received {len(results)} annotated results\")\n",
    "    return results\n",
    "\n",
    "# Monitor for annotated results\n",
    "annotated_results = monitor_annotated_results(consumer, duration_seconds=20)\n",
    "\n",
    "if annotated_results:\n",
    "    df_results = pd.DataFrame(annotated_results)\n",
    "    print(\"\\nüìä Annotated Results Summary:\")\n",
    "    print(df_results.head())\n",
    "else:\n",
    "    print(\"\\nüìù No annotated results received yet. VEP service may be processing or starting up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scaling Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigger_scaling_event(producer, num_sequences=50, processing_mode='big-data'):\n",
    "    \"\"\"Send a large batch to trigger KEDA scaling\"\"\"\n",
    "    print(f\"üöÄ Triggering scaling event with {num_sequences} sequences in {processing_mode} mode...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    sent_sequences = send_genetic_data_batch(producer, num_sequences, processing_mode)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"\\n‚ö° Scaling trigger completed:\")\n",
    "    print(f\"   üì§ Sent: {len(sent_sequences)} sequences\")\n",
    "    print(f\"   ‚è±Ô∏è Time: {end_time - start_time:.2f} seconds\")\n",
    "    print(f\"   üìä Rate: {len(sent_sequences)/(end_time - start_time):.1f} sequences/second\")\n",
    "    print(f\"   üéØ Mode: {processing_mode}\")\n",
    "    \n",
    "    return sent_sequences\n",
    "\n",
    "# Trigger a scaling event\n",
    "scaling_sequences = trigger_scaling_event(producer, num_sequences=20, processing_mode='big-data')\n",
    "\n",
    "print(\"\\nüîç This should trigger:\")\n",
    "print(\"   üìà VEP service pod scaling (KEDA)\")\n",
    "print(\"   üìä Increased Kafka consumer lag\")\n",
    "print(\"   üí∞ Cost attribution changes\")\n",
    "print(\"   ‚ö° Potential node scaling if needed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
